from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col
from pyspark.sql.types import StructType, StructField, StringType, DoubleType

# 1Ô∏è‚É£ Create Spark session
spark = SparkSession.builder.appName("RideSharingAnalytics_Task1").getOrCreate()

# 2Ô∏è‚É£ Define schema for incoming JSON data
schema = StructType([
    StructField("trip_id", StringType(), True),
    StructField("driver_id", StringType(), True),
    StructField("distance_km", DoubleType(), True),
    StructField("fare_amount", DoubleType(), True),
    StructField("timestamp", StringType(), True)
])

# 3Ô∏è‚É£ Read streaming data from socket
data = (
    spark.readStream
    .format("socket")
    .option("host", "localhost")
    .option("port", 9999)
    .load()
)

# 4Ô∏è‚É£ Parse JSON data into structured columns
parsed_data = (
    data.select(from_json(col("value").cast("string"), schema).alias("data"))
        .select("data.*")
)

# 5Ô∏è‚É£ Write parsed data to CSV files inside outputs/task1/
query_task1 = (
    parsed_data.writeStream
    .format("csv")
    .outputMode("append")
    .option("header", "true")
    .option("path", "outputs/task1/")                     # üëà matches your structure
    .option("checkpointLocation", "checkpoints/task1/")   # üëà checkpoint folder inside checkpoints/
    .start()
)

# 6Ô∏è‚É£ Keep the stream running
query_task1.awaitTermination()